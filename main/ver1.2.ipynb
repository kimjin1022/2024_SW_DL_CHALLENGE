{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdf2xXO78pch",
    "outputId": "67be29c9-083c-476a-a1f5-3026a82664b9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "import os, json, open_clip, torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import open_clip\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 254/254 [00:51<00:00,  4.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# 0. Settings\n",
    "device = 'cuda:0'\n",
    "model_name = 'ViT-L-14'\n",
    "pretrained = 'openai'\n",
    "root = './'\n",
    "dataset_name = 'Scene'\n",
    "\n",
    "# 1. Load CLIP model\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "\n",
    "# 2. Load test dataset with data augmentation\n",
    "ds = ImageFolder(os.path.join(root, dataset_name), transform=preprocess)\n",
    "ds.samples = natsorted(ds.samples)\n",
    "dl = DataLoader(ds, shuffle=False, batch_size=32, num_workers=2)\n",
    "\n",
    "# 3. Load class name list\n",
    "with open(os.path.join(root, 'classes.json'), 'r') as j:\n",
    "     class_names = json.loads(j.read())\n",
    "\n",
    "# Enhanced text prompts with detailed descriptions\n",
    "class_descriptions = {\n",
    "    \"Buildings\": \"A photo of buildings, which can include skyscrapers, residential houses, or office complexes. These structures are designed for various human activities and can be found in urban or suburban areas.\",\n",
    "    \"Forests\": \"A photo of a forest, showcasing a dense collection of trees, plants, and wildlife. Forests can vary from tropical rainforests to temperate woodlands, providing habitats for numerous species.\",\n",
    "    \"Glacier\": \"A photo of a glacier, featuring large masses of ice and snow, often found in polar regions or high mountains. Glaciers slowly move over land, shaping the landscape through erosion.\",\n",
    "    \"Mountains\": \"A photo of mountains, displaying tall, rugged peaks, rocky terrain, and often snow-capped summits. Mountains are formed through tectonic forces and are a prominent feature of the Earth's surface.\",\n",
    "    \"Sea\": \"A photo of the sea, depicting vast expanses of saltwater, waves, and sometimes coastal features like beaches or cliffs. The sea is a critical component of the Earth's hydrosphere and supports a diverse range of marine life.\",\n",
    "    \"Street\": \"A photo of a street, including elements like roads, buildings, cars, and people. Streets are essential parts of urban and suburban infrastructure, facilitating transportation and social interaction.\"\n",
    "}\n",
    "\n",
    "# Detailed prompts\n",
    "prompts = [class_descriptions[class_name] for class_name in class_names]\n",
    "\n",
    "# 4. Perform zero-shot classification\n",
    "zero_shot_top1 = 0\n",
    "submission = dict({'id_idx': list(range(8100)), 'label': []})\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    text = tokenizer(prompts)\n",
    "    text_features = model.encode_text(text)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    model = model.to(device)\n",
    "    for x, y in tqdm(dl):\n",
    "        x = x.cuda(device)\n",
    "        image_features = model.encode_image(x).to('cpu').float()\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        zero_shot_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        zero_shot_pred = zero_shot_probs.max(dim=-1)[1].tolist()\n",
    "        submission['label'] += zero_shot_pred\n",
    "\n",
    "# 5. Save prediction as submission.scv file.\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f'submission_{current_time}.csv'\n",
    "pd.DataFrame(submission).to_csv(os.path.join(root+\"submissions/\", file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "w2zS1z71y653"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
