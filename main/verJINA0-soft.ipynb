{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32afbf9-808e-4b48-a9d0-a8479716cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5635972\n",
      "0.2905935\n",
      "0.05685927\n",
      "0.12773362\n",
      "0.2915658\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers einops timm pillow\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModel.from_pretrained('jinaai/jina-clip-v1', trust_remote_code=True)\n",
    "\n",
    "# New meaningful sentences\n",
    "sentences = ['A blue cat', 'A red cat']\n",
    "\n",
    "# Public image URLs\n",
    "image_urls = [\n",
    "    'https://i.pinimg.com/600x315/21/48/7e/21487e8e0970dd366dafaed6ab25d8d8.jpg',\n",
    "    'https://i.pinimg.com/736x/c9/f2/3e/c9f23e212529f13f19bad5602d84b78b.jpg'\n",
    "]\n",
    "\n",
    "# Encode text and images\n",
    "text_embeddings = model.encode_text(sentences)\n",
    "image_embeddings = model.encode_image(image_urls)  # also accepts PIL.image, local filenames, dataURI\n",
    "\n",
    "# Compute similarities\n",
    "print(text_embeddings[0] @ text_embeddings[1].T) # text embedding similarity\n",
    "print(text_embeddings[0] @ image_embeddings[0].T) # text-image cross-modal similarity\n",
    "print(text_embeddings[0] @ image_embeddings[1].T) # text-image cross-modal similarity\n",
    "print(text_embeddings[1] @ image_embeddings[0].T) # text-image cross-modal similarity\n",
    "print(text_embeddings[1] @ image_embeddings[1].T)# text-image cross-modal similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7135b511-9486-4ca2-973c-25ecca3be01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1893, 0.0478, 0.0434, 0.0912, 0.0652, 0.5631],\n",
      "        [0.7001, 0.0112, 0.0320, 0.1071, 0.0651, 0.0846]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 레이블 리스트\n",
    "labels_list = ['Buildings', 'Forests', 'Glacier', 'Mountains', 'Sea', 'Street']\n",
    "\n",
    "# 이미지 리스트\n",
    "images = [\"./Scene/0/0.jpg\", \"./Scene/0/1.jpg\"]\n",
    "\n",
    "# 텍스트 및 이미지 임베딩 계산\n",
    "text_embeddings = model.encode_text(labels_list)\n",
    "image_embeddings = model.encode_image(images)\n",
    "\n",
    "# 결과 계산 (점수 매트릭스)\n",
    "rst = 20 * image_embeddings @ text_embeddings.T\n",
    "\n",
    "# numpy.ndarray를 torch.Tensor로 변환\n",
    "rst = torch.tensor(rst)\n",
    "\n",
    "# 소프트맥스 함수 적용 (차원=1, 각 행에 대해 확률 계산)\n",
    "softmax_probs = F.softmax(rst, dim=1)\n",
    "\n",
    "# 출력: softmax 결과 확인\n",
    "print(softmax_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f68a7f4-8e8b-4872-8e7d-afa1f11df419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "145b163b-6419-40c3-87cd-a61ba758cfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(98.5356, grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.logit_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f194938-27ca-4e53-ac61-7845bbad206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([0.2005, 0.1008, 0.0961, 0.1392, 0.1176, 0.3458])\n",
      "tensor([0.4195, 0.0531, 0.0897, 0.1641, 0.1279, 0.1458])\n",
      "tensor([0.0577, 0.4277, 0.1364, 0.1162, 0.1372, 0.1247])\n",
      "tensor([0.2798, 0.0773, 0.2220, 0.0879, 0.1207, 0.2123])\n",
      "tensor([0.0499, 0.0841, 0.2467, 0.3115, 0.2542, 0.0536])\n",
      "tensor([0.1031, 0.3425, 0.1254, 0.1536, 0.0871, 0.1883])\n",
      "tensor([0.4888, 0.0609, 0.0724, 0.0638, 0.0663, 0.2478])\n",
      "tensor([0.0379, 0.0781, 0.2587, 0.4989, 0.0993, 0.0271])\n",
      "tensor([0.0610, 0.4874, 0.0989, 0.1078, 0.0968, 0.1481])\n",
      "tensor([0.0577, 0.1088, 0.2319, 0.3656, 0.1534, 0.0824])\n",
      "tensor([0.2522, 0.1069, 0.1622, 0.1465, 0.1485, 0.1837])\n",
      "tensor([0.0719, 0.0460, 0.1301, 0.1015, 0.5912, 0.0592])\n",
      "tensor([0.0698, 0.0736, 0.1388, 0.2326, 0.4297, 0.0556])\n",
      "tensor([0.2789, 0.0637, 0.0576, 0.0961, 0.0497, 0.4540])\n",
      "tensor([0.0404, 0.1126, 0.2019, 0.5167, 0.0984, 0.0299])\n",
      "tensor([0.1091, 0.0578, 0.3574, 0.2390, 0.1729, 0.0639])\n",
      "tensor([0.5538, 0.0394, 0.0997, 0.0971, 0.0718, 0.1381])\n",
      "tensor([0.1325, 0.0547, 0.0835, 0.0655, 0.0640, 0.5997])\n",
      "tensor([0.1185, 0.1162, 0.1664, 0.4126, 0.1089, 0.0775])\n",
      "tensor([0.2687, 0.0593, 0.1352, 0.1560, 0.1524, 0.2284])\n",
      "tensor([0.0695, 0.0685, 0.3521, 0.1628, 0.1953, 0.1519])\n",
      "tensor([0.2262, 0.1206, 0.1003, 0.2264, 0.1184, 0.2081])\n",
      "tensor([0.5022, 0.0443, 0.0600, 0.1218, 0.1138, 0.1580])\n",
      "tensor([0.1162, 0.3799, 0.1267, 0.1704, 0.1151, 0.0916])\n",
      "tensor([0.3989, 0.0500, 0.1224, 0.1975, 0.1096, 0.1215])\n",
      "tensor([0.1246, 0.3309, 0.1404, 0.1823, 0.0996, 0.1221])\n",
      "tensor([0.0853, 0.0817, 0.2178, 0.3550, 0.1861, 0.0741])\n",
      "tensor([0.0554, 0.5863, 0.0711, 0.1284, 0.0797, 0.0792])\n",
      "tensor([0.1127, 0.1776, 0.1939, 0.1850, 0.0980, 0.2329])\n",
      "tensor([0.1231, 0.0628, 0.3089, 0.2888, 0.0999, 0.1164])\n",
      "tensor([0.0418, 0.0773, 0.1406, 0.2368, 0.4474, 0.0562])\n",
      "tensor([0.1051, 0.0607, 0.1306, 0.1632, 0.4425, 0.0978])\n",
      "tensor([0.1425, 0.0839, 0.1121, 0.1586, 0.1314, 0.3716])\n",
      "tensor([0.4990, 0.0695, 0.1077, 0.0965, 0.1197, 0.1076])\n",
      "tensor([0.0914, 0.1308, 0.1459, 0.3353, 0.2423, 0.0543])\n",
      "tensor([0.1242, 0.0913, 0.2344, 0.2155, 0.1911, 0.1435])\n",
      "tensor([0.1221, 0.0584, 0.1560, 0.1358, 0.4645, 0.0632])\n",
      "tensor([0.1072, 0.3079, 0.1388, 0.1814, 0.1046, 0.1602])\n",
      "tensor([0.0710, 0.0514, 0.4168, 0.2045, 0.2189, 0.0375])\n",
      "tensor([0.2427, 0.0742, 0.0496, 0.1214, 0.0894, 0.4227])\n",
      "tensor([0.2374, 0.0407, 0.0671, 0.0677, 0.0522, 0.5349])\n",
      "tensor([0.0692, 0.1024, 0.1772, 0.3684, 0.1941, 0.0887])\n",
      "tensor([0.1058, 0.1223, 0.1443, 0.3404, 0.1582, 0.1289])\n",
      "tensor([0.0678, 0.0507, 0.4249, 0.1732, 0.2260, 0.0575])\n",
      "tensor([0.2011, 0.2171, 0.1268, 0.2347, 0.0974, 0.1229])\n",
      "tensor([0.0959, 0.3543, 0.1203, 0.1575, 0.1101, 0.1619])\n",
      "tensor([0.0670, 0.0693, 0.4025, 0.2213, 0.1826, 0.0573])\n",
      "tensor([0.0348, 0.0536, 0.2389, 0.2878, 0.3474, 0.0376])\n",
      "tensor([0.1776, 0.1128, 0.1324, 0.3944, 0.1067, 0.0762])\n",
      "tensor([0.0831, 0.1177, 0.2456, 0.2612, 0.1020, 0.1904])\n",
      "tensor([0.0345, 0.0998, 0.1962, 0.2452, 0.3731, 0.0511])\n",
      "tensor([0.5369, 0.0374, 0.0546, 0.0502, 0.0564, 0.2644])\n",
      "tensor([0.0797, 0.0784, 0.2265, 0.3730, 0.1624, 0.0799])\n",
      "tensor([0.0382, 0.0553, 0.1045, 0.1607, 0.6031, 0.0382])\n",
      "tensor([0.0456, 0.1230, 0.1663, 0.2048, 0.3980, 0.0622])\n",
      "tensor([0.2847, 0.0749, 0.1592, 0.1253, 0.1878, 0.1680])\n",
      "tensor([0.0362, 0.6456, 0.0640, 0.0911, 0.0732, 0.0899])\n",
      "tensor([0.0912, 0.0786, 0.2679, 0.4066, 0.0777, 0.0781])\n",
      "tensor([0.2410, 0.0837, 0.0716, 0.0806, 0.0526, 0.4705])\n",
      "tensor([0.1613, 0.0805, 0.1147, 0.0949, 0.0958, 0.4527])\n",
      "tensor([0.2655, 0.1176, 0.1500, 0.1842, 0.1057, 0.1770])\n",
      "tensor([0.1586, 0.1413, 0.1889, 0.2332, 0.0790, 0.1991])\n",
      "tensor([0.1831, 0.1835, 0.0749, 0.1048, 0.0809, 0.3729])\n",
      "tensor([0.1054, 0.0938, 0.2561, 0.1846, 0.2323, 0.1277])\n",
      "tensor([0.4413, 0.0394, 0.0724, 0.0673, 0.0725, 0.3072])\n",
      "tensor([0.1182, 0.2911, 0.1400, 0.1952, 0.1160, 0.1396])\n",
      "tensor([0.2845, 0.0509, 0.0488, 0.0977, 0.0699, 0.4482])\n",
      "tensor([0.1521, 0.0312, 0.0594, 0.0655, 0.0590, 0.6328])\n",
      "tensor([0.1659, 0.0911, 0.0925, 0.1383, 0.1142, 0.3980])\n",
      "tensor([0.0611, 0.0781, 0.4089, 0.1445, 0.1410, 0.1664])\n",
      "tensor([0.1363, 0.1220, 0.1841, 0.1211, 0.1684, 0.2681])\n",
      "tensor([0.2180, 0.1057, 0.1851, 0.1955, 0.1343, 0.1613])\n",
      "tensor([0.1786, 0.1881, 0.1844, 0.2431, 0.0683, 0.1375])\n",
      "tensor([0.1845, 0.1100, 0.0777, 0.1141, 0.0883, 0.4255])\n",
      "tensor([0.1020, 0.1898, 0.1210, 0.3808, 0.1305, 0.0760])\n",
      "tensor([0.2364, 0.1390, 0.0896, 0.1562, 0.0843, 0.2945])\n",
      "tensor([0.1713, 0.2312, 0.1571, 0.1820, 0.1396, 0.1188])\n",
      "tensor([0.0944, 0.1046, 0.2378, 0.2370, 0.2066, 0.1195])\n",
      "tensor([0.1166, 0.4103, 0.1029, 0.1319, 0.0784, 0.1600])\n",
      "tensor([0.2158, 0.0785, 0.0634, 0.1033, 0.0748, 0.4643])\n",
      "tensor([0.3289, 0.0797, 0.2081, 0.1345, 0.0991, 0.1496])\n",
      "tensor([0.3616, 0.0891, 0.1235, 0.1367, 0.0882, 0.2008])\n",
      "tensor([0.1684, 0.0670, 0.2477, 0.2142, 0.1629, 0.1398])\n",
      "tensor([0.5276, 0.0528, 0.0618, 0.1258, 0.1112, 0.1209])\n",
      "tensor([0.0808, 0.3889, 0.1043, 0.1606, 0.0889, 0.1765])\n",
      "tensor([0.0465, 0.5248, 0.0841, 0.1186, 0.1135, 0.1124])\n",
      "tensor([0.5096, 0.0668, 0.0685, 0.1034, 0.0733, 0.1785])\n",
      "tensor([0.1492, 0.1773, 0.1202, 0.1873, 0.1695, 0.1964])\n",
      "tensor([0.3524, 0.0794, 0.1154, 0.2184, 0.1437, 0.0907])\n",
      "tensor([0.1375, 0.0869, 0.2453, 0.2417, 0.1322, 0.1564])\n",
      "tensor([0.0827, 0.0756, 0.3244, 0.3288, 0.1073, 0.0811])\n",
      "tensor([0.0806, 0.1027, 0.1655, 0.2108, 0.3119, 0.1285])\n",
      "tensor([0.0328, 0.1352, 0.2177, 0.4916, 0.0898, 0.0329])\n",
      "tensor([0.1291, 0.3879, 0.0969, 0.1765, 0.0694, 0.1401])\n",
      "tensor([0.2124, 0.2520, 0.1368, 0.1665, 0.0800, 0.1523])\n",
      "tensor([0.1121, 0.0587, 0.2454, 0.2516, 0.2350, 0.0972])\n",
      "tensor([0.3565, 0.1289, 0.1451, 0.1249, 0.0951, 0.1494])\n",
      "tensor([0.4997, 0.0633, 0.1057, 0.1289, 0.0808, 0.1216])\n",
      "tensor([0.0703, 0.0740, 0.3330, 0.2976, 0.1621, 0.0630])\n",
      "tensor([0.1901, 0.1078, 0.1503, 0.1123, 0.0922, 0.3473])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3215384/2986928042.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  text_probs = F.softmax(image_embeddings @ text_embeddings.T * 10)\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "submission = dict({'id_idx': [], 'label': []})\n",
    "\n",
    "for idx in range(81):\n",
    "    print(idx+1, end=\" \")\n",
    "    images = []\n",
    "    for i in range(100):\n",
    "        images.append(f\"./Scene/0/{idx*100 + i}.jpg\")    \n",
    "    image_embeddings = torch.tensor(model.encode_image(images))\n",
    "    \n",
    "    text_probs = F.softmax(image_embeddings @ text_embeddings.T * 10)\n",
    "\n",
    "    for i in text_probs:\n",
    "        print(i)\n",
    "    break\n",
    "    rst = text_probs.tolist()\n",
    "    submission['label'] += rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca26e06f-cf23-4073-8abb-3a63acc6c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'JINA_soft_{current_time}.csv'\n",
    "submission['id_idx'] = list(range(len(submission['label'])))\n",
    "pd.DataFrame(submission).to_csv(os.path.join(\"./submissions/\", file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
