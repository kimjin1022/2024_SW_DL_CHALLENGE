{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0547864-9641-4089-87f6-7808371df994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from transformers import CLIPImageProcessor, pipeline, CLIPTokenizer\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "image_path = f\"./Scene/0/{0}.jpg\"\n",
    "model_name_or_path = \"BAAI/EVA-CLIP-8B\" # or /path/to/local/EVA-CLIP-8B\n",
    "image_size = 224\n",
    "\n",
    "processor = CLIPImageProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad46a549-6c7f-4e7b-a258-9a4c946576e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a30419290094fff8a4afebffbfbba79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    torch_dtype=torch.float32,\n",
    "    trust_remote_code=True).to('cpu').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20d36f5-e775-4163-ba12-5939d41d6ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinjinjara1022/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(image_path)\n",
    "class_names=['building', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "\n",
    "prompts = []\n",
    "for class_name in class_names:\n",
    "    prompts.extend([\n",
    "        f\"A photo of a {class_name}\",\n",
    "        f\"An image depicting a {class_name}\",\n",
    "        f\"A scenic view of {class_name}\",\n",
    "        f\"A {class_name} landscape\",\n",
    "        f\"A snapshot of a {class_name}\",\n",
    "        f\"A beautiful {class_name} scene\",\n",
    "        f\"An artistic representation of {class_name}\",\n",
    "        f\"A {class_name} captured in nature\",\n",
    "        f\"A {class_name} during sunset\",\n",
    "        f\"A serene {class_name} environment\"\n",
    "    ])\n",
    "\n",
    "image1 = Image.open(f\"./Scene/0/{0}.jpg\")\n",
    "image2 = Image.open(f\"./Scene/0/{1}.jpg\")\n",
    "\n",
    "images = [image1, image2]\n",
    "tokenizer = CLIPTokenizer.from_pretrained(model_name_or_path)\n",
    "input_ids = tokenizer(prompts,  return_tensors=\"pt\", padding=True, truncation=True, max_length=50).input_ids.to('cpu')\n",
    "input_pixels = processor(images=images, return_tensors=\"pt\").pixel_values.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99220710-2a52-406e-940c-46ca7ca54fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), torch.amp.autocast('cuda'):\n",
    "    image_features = model.encode_image(input_pixels)\n",
    "    text_features = model.encode_text(input_ids)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "label_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "predict = label_probs.argmax(axis=1) // 10\n",
    "predict = predict.numpy().astype(int).tolist()\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc922fb1-5c08-4fa4-8e07-9174e4ebfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9e654b9-5a3e-49ea-8e5d-ba2035360e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710 720 730 740 750 760 770 780 790 800 "
     ]
    }
   ],
   "source": [
    "submission = dict({'id_idx': [], 'label': []})\n",
    "start_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f'submission_{start_time}_ver4_1.csv'\n",
    "\n",
    "for idx in range(0, 810, 10):\n",
    "    print(idx, end=\" \")\n",
    "    images = []\n",
    "    for i in range(10):\n",
    "        images.append(Image.open(f\"./Scene/0/{idx + i}.jpg\"))\n",
    "        \n",
    "    tokenizer = CLIPTokenizer.from_pretrained(model_name_or_path)\n",
    "    input_ids = tokenizer(prompts,  return_tensors=\"pt\", padding=True, truncation=True, max_length=50).input_ids.to('cpu')\n",
    "    input_pixels = processor(images=images, return_tensors=\"pt\").pixel_values.to('cpu')\n",
    "        \n",
    "    with torch.no_grad(), torch.amp.autocast('cuda'):\n",
    "        image_features = model.encode_image(input_pixels)\n",
    "        text_features = model.encode_text(input_ids)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    label_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    predict = label_probs.argmax(axis=1) // 10\n",
    "    predict = predict.numpy().astype(int).tolist()  \n",
    "\n",
    "    submission['label'] += predict\n",
    "    submission['id_idx'] = list(range(len(submission['label'])))\n",
    "    pd.DataFrame(submission).to_csv(os.path.join(\"/home/jinjinjara1022/ajou/submissions/\", file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
