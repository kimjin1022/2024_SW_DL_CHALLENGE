{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60246d3f-1495-416e-989f-914ef9952ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fef6753-9360-4c77-a677-fa0428168b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e122720439b044fcbf1d0b2e619f5dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Blip2ForConditionalGeneration(\n",
       "  (vision_model): Blip2VisionModel(\n",
       "    (embeddings): Blip2VisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (encoder): Blip2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-38): 39 x Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (qformer): Blip2QFormerModel(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (encoder): Blip2QFormerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (language_projection): Linear(in_features=768, out_features=2048, bias=True)\n",
       "  (language_model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 2048)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 2048)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 32)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-23): 23 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 2048)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 32)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-23): 23 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2048, out_features=32128, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:3\"\n",
    "\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "model.to(device, torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d95ae29-95a6-45a6-80df-4e3f284afffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from natsort import natsorted\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5208e332-370a-4a19-b54c-4b188db94118",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./\", 'classes.json'), 'r') as j:\n",
    "    class_names = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bbcf092-8586-4573-8054-f1026caf118e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Buildings', 'Forests', 'Glacier', 'Mountains', 'Sea', 'Street']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a03971-90b2-4b56-a9d8-e4d82e8d9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f\"./Scene/0/{238}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "006b69fe-16ba-4617-8e09-04f045ca7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(img_path).convert('RGB')\n",
    "prompt1 = \"Please describe the scene.\"\n",
    "prompt2 = \"Please describe the image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31d1f083-c005-4b68-b732-7b7cbab1726a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "604de6d3-6f21-4d5e-9cc7-1c10073385ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, text=[prompt1], return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4074aaa7-8462-4a45-96b8-6644e99aef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dbff14af-4d6e-4631-89be-40fca8206fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5e415ac3-c4ad-4258-be60-2292e5dcf9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a sand beach with a sand beach and a sand'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4baeb75d-8094-4444-8fca-a9fb648aaecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a sand beach with a sand beach and a sand : Sea\n"
     ]
    }
   ],
   "source": [
    "output = zeroshot_classifier(generated_text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "print(f\"{generated_text} : {output['labels'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c4153c2-72ef-4f90-b620-796906c1f143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2index('a buildings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "baac2758-198b-47cd-9e2d-d6a7a0e5a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2index(gen_text):\n",
    "    classes = ['Buildings', 'Forests', 'Glacier', 'Mountains', 'Sea', 'Street']\n",
    "    for idx, text in enumerate(classes):\n",
    "        if text == gen_text:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cced489-a03e-425f-81ab-ea77f7178371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Angela Merkel is a politician in Germany and leader of the CDU', 'labels': ['Sea', 'Buildings', 'Street', 'Mountains', 'Forests', 'Glacier'], 'scores': [0.2592664659023285, 0.22068199515342712, 0.1661624312400818, 0.148606538772583, 0.11095580458641052, 0.09432673454284668]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "text = \"Angela Merkel is a politician in Germany and leader of the CDU\"\n",
    "hypothesis_template = \"{}\"\n",
    "classes_verbalized = ['Buildings', 'Forests', 'Glacier', 'Mountains', 'Sea', 'Street']\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")  # change the model identifier here\n",
    "output = zeroshot_classifier(text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6fe919f-33fa-4585-9f34-5da051dba4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     12\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mzeroshot_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses_verbalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypothesis_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print(f\"{generated_text} : {output['labels'][0]}\")\u001b[39;00m\n\u001b[1;32m     16\u001b[0m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [text2index(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1249\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1164\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1163\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1164\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1297\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1297\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m encoder_layer \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1309\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1063\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m   1055\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1056\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1057\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1061\u001b[0m )\n\u001b[0;32m-> 1063\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:507\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    497\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    498\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    499\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m         output_attentions,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    517\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:355\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    348\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m ):\n\u001b[0;32m--> 355\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    364\u001b[0m         attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:286\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    285\u001b[0m ):\n\u001b[0;32m--> 286\u001b[0m     self_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    295\u001b[0m         self_output, att_matrix \u001b[38;5;241m=\u001b[39m self_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:714\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention:\n\u001b[1;32m    713\u001b[0m     rel_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_dropout(rel_embeddings)\n\u001b[0;32m--> 714\u001b[0m     rel_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisentangled_attention_bias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rel_att \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m rel_att\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:769\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.disentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_att_key:\n\u001b[1;32m    766\u001b[0m     pos_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_proj(rel_embeddings), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads\n\u001b[1;32m    768\u001b[0m     )\u001b[38;5;241m.\u001b[39mrepeat(query_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 769\u001b[0m     pos_key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads)\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[1;32m    770\u001b[0m         query_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    771\u001b[0m     )\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc2p\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_att_type:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "img_nums = 8100\n",
    "submission = dict({'id_idx': [], 'label': []})\n",
    "\n",
    "for idx in range(img_nums):\n",
    "    img_path = f\"./Scene/0/{idx}.jpg\"\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    prompt = \"Please describe the scene.\"\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=20)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "    \n",
    "    output = zeroshot_classifier(generated_text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "    #print(f\"{generated_text} : {output['labels'][0]}\")\n",
    "    submission['label'] += [text2index(output['labels'][0])]\n",
    "    \n",
    "    if (idx+1)%100 == 0:\n",
    "        file_name = f'submission_{current_time}.csv'\n",
    "        submission['id_idx'] = list(range(len(submission['label'])))\n",
    "        pd.DataFrame(submission).to_csv(os.path.join(\"./submissions/\", file_name), index=False)\n",
    "        print(idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fc153-a48b-4715-b02b-a91a1f55ca20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
