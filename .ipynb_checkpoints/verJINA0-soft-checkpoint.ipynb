{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32afbf9-808e-4b48-a9d0-a8479716cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5635972\n",
      "0.2905935\n",
      "0.05685927\n",
      "0.12773362\n",
      "0.2915658\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers einops timm pillow\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModel.from_pretrained('jinaai/jina-clip-v1', trust_remote_code=True)\n",
    "\n",
    "# New meaningful sentences\n",
    "sentences = ['A blue cat', 'A red cat']\n",
    "\n",
    "# Public image URLs\n",
    "image_urls = [\n",
    "    'https://i.pinimg.com/600x315/21/48/7e/21487e8e0970dd366dafaed6ab25d8d8.jpg',\n",
    "    'https://i.pinimg.com/736x/c9/f2/3e/c9f23e212529f13f19bad5602d84b78b.jpg'\n",
    "]\n",
    "\n",
    "# Encode text and images\n",
    "text_embeddings = model.encode_text(sentences)\n",
    "image_embeddings = model.encode_image(image_urls)  # also accepts PIL.image, local filenames, dataURI\n",
    "\n",
    "# Compute similarities\n",
    "print(text_embeddings[0] @ text_embeddings[1].T) # text embedding similarity\n",
    "print(text_embeddings[0] @ image_embeddings[0].T) # text-image cross-modal similarity\n",
    "print(text_embeddings[0] @ image_embeddings[1].T) # text-image cross-modal similarity\n",
    "print(text_embeddings[1] @ image_embeddings[0].T) # text-image cross-modal similarity\n",
    "print(text_embeddings[1] @ image_embeddings[1].T)# text-image cross-modal similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7135b511-9486-4ca2-973c-25ecca3be01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1715, 0.1601, 0.1593, 0.1654, 0.1626, 0.1811],\n",
      "        [0.1863, 0.1515, 0.1596, 0.1696, 0.1654, 0.1676]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 레이블 리스트\n",
    "labels_list = ['Buildings', 'Forests', 'Glacier', 'Mountains', 'Sea', 'Street']\n",
    "\n",
    "# 이미지 리스트\n",
    "images = [\"./Scene/0/0.jpg\", \"./Scene/0/1.jpg\"]\n",
    "\n",
    "# 텍스트 및 이미지 임베딩 계산\n",
    "text_embeddings = model.encode_text(labels_list)\n",
    "image_embeddings = model.encode_image(images)\n",
    "\n",
    "# 결과 계산 (점수 매트릭스)\n",
    "rst = image_embeddings @ text_embeddings.T\n",
    "\n",
    "# numpy.ndarray를 torch.Tensor로 변환\n",
    "rst = torch.tensor(rst)\n",
    "\n",
    "# 소프트맥스 함수 적용 (차원=1, 각 행에 대해 확률 계산)\n",
    "softmax_probs = F.softmax(rst, dim=1)\n",
    "\n",
    "# 출력: softmax 결과 확인\n",
    "print(softmax_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f68a7f4-8e8b-4872-8e7d-afa1f11df419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "145b163b-6419-40c3-87cd-a61ba758cfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(98.5356, grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.logit_scale.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f194938-27ca-4e53-ac61-7845bbad206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "submission = dict({'id_idx': [], 'label': []})\n",
    "\n",
    "for idx in range(81):\n",
    "    print(idx+1, end=\" \")\n",
    "    images = []\n",
    "    for i in range(100):\n",
    "        images.append(f\"./Scene/0/{idx*100 + i}.jpg\")\n",
    "        \n",
    "    image_embeddings = model.encode_image(images)\n",
    "    rst = int(model.logit_scale.exp()) * image_embeddings @ text_embeddings.T\n",
    "    rst = torch.tensor(rst)\n",
    "    softmax_probs = F.softmax(rst, dim=1)\n",
    "    rst = softmax_probs.tolist()\n",
    "    submission['label'] += rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca26e06f-cf23-4073-8abb-3a63acc6c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'JINA_soft_{current_time}.csv'\n",
    "submission['id_idx'] = list(range(len(submission['label'])))\n",
    "pd.DataFrame(submission).to_csv(os.path.join(\"./submissions/\", file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
